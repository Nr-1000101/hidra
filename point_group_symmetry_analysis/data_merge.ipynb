{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37596888-9bda-47d2-8ed3-49c6be10a5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring HDF5 file: mol3d_data/molecules3d_million_1.h5\n",
      "--------------------------------------------------\n",
      "Dataset: 'atom_types' - 999949 entries, dtype: object\n",
      "Dataset: 'coords' - 999949 entries, dtype: object\n",
      "Dataset: 'selfies' - 999949 entries, dtype: object\n",
      "Dataset: 'smiles' - 999949 entries, dtype: object\n",
      "\n",
      "Total items found: 4\n",
      "Loaded JSON file: mol3d_data/final/point_groups_million_1_final.json\n",
      "JSON data length: 999949 items\n",
      "Successfully added dataset 'point_groups' to HDF5 file\n",
      "Dataset shape: (999949,), dtype: object\n",
      "\n",
      "Updated HDF5 file structure:\n",
      "Exploring HDF5 file: mol3d_data/molecules3d_million_1.h5\n",
      "--------------------------------------------------\n",
      "Dataset: 'atom_types' - 999949 entries, dtype: object\n",
      "Dataset: 'coords' - 999949 entries, dtype: object\n",
      "Dataset: 'point_groups' - 999949 entries, dtype: object\n",
      "Dataset: 'selfies' - 999949 entries, dtype: object\n",
      "Dataset: 'smiles' - 999949 entries, dtype: object\n",
      "\n",
      "Total items found: 5\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def explore_h5_file(h5_filepath):\n",
    "    \"\"\"\n",
    "    Open an HDF5 file and report the names of datasets/groups and their entries.\n",
    "    \n",
    "    Args:\n",
    "        h5_filepath (str): Path to the HDF5 file\n",
    "    \n",
    "    Returns:\n",
    "        dict: Information about the HDF5 file structure\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with h5py.File(h5_filepath, 'r') as h5_file:\n",
    "            print(f\"Exploring HDF5 file: {h5_filepath}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            file_info = {}\n",
    "            \n",
    "            def visit_item(name, obj):\n",
    "                if isinstance(obj, h5py.Dataset):\n",
    "                    entries = obj.shape[0] if obj.shape else 1\n",
    "                    dtype = obj.dtype\n",
    "                    print(f\"Dataset: '{name}' - {entries} entries, dtype: {dtype}\")\n",
    "                    file_info[name] = {\n",
    "                        'type': 'dataset',\n",
    "                        'entries': entries,\n",
    "                        'shape': obj.shape,\n",
    "                        'dtype': str(dtype)\n",
    "                    }\n",
    "                elif isinstance(obj, h5py.Group):\n",
    "                    print(f\"Group: '{name}'\")\n",
    "                    file_info[name] = {\n",
    "                        'type': 'group'\n",
    "                    }\n",
    "            \n",
    "            h5_file.visititems(visit_item)\n",
    "            \n",
    "            print(f\"\\nTotal items found: {len(file_info)}\")\n",
    "            return file_info\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{h5_filepath}' not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading HDF5 file: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_json_and_add_to_h5(json_filepath, h5_filepath, dataset_name='point_groups'):\n",
    "    \"\"\"\n",
    "    Load JSON data and insert it as a new dataset in an HDF5 file.\n",
    "    \n",
    "    Args:\n",
    "        json_filepath (str): Path to the JSON file\n",
    "        h5_filepath (str): Path to the HDF5 file\n",
    "        dataset_name (str): Name for the new dataset in HDF5 file\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load JSON data\n",
    "        with open(json_filepath, 'r') as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "        print(f\"Loaded JSON file: {json_filepath}\")\n",
    "\n",
    "        json_data = [pg.replace(\"C∞v\", \"Cnv\").replace(\"D∞h\", \"Dnh\") for pg in json_data]\n",
    "        \n",
    "        # Determine data length and structure\n",
    "        if isinstance(json_data, list):\n",
    "            data_length = len(json_data)\n",
    "            print(f\"JSON data length: {data_length} items\")\n",
    "            np_data = np.array(json_data, dtype=h5py.string_dtype(encoding='utf-8'))\n",
    "                \n",
    "        \n",
    "        # Add data to HDF5 file\n",
    "        with h5py.File(h5_filepath, 'a') as h5_file:  # 'a' for append mode\n",
    "            \n",
    "            # Check if dataset already exists\n",
    "            if dataset_name in h5_file:\n",
    "                print(f\"Warning: Dataset '{dataset_name}' already exists. Overwriting...\")\n",
    "                del h5_file[dataset_name]\n",
    "            \n",
    "            # Create new dataset\n",
    "            h5_file.create_dataset(dataset_name, data=np_data)\n",
    "            print(f\"Successfully added dataset '{dataset_name}' to HDF5 file\")\n",
    "            print(f\"Dataset shape: {np_data.shape}, dtype: {np_data.dtype}\")\n",
    "            \n",
    "        return True\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: File not found - {e}\")\n",
    "        return False\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error: Invalid JSON format - {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing files: {e}\")\n",
    "        return False\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example 1: Explore an HDF5 file\n",
    "    mil = 1\n",
    "    h5_file_path = f\"mol3d_data/molecules3d_million_{mil}.h5\"\n",
    "    file_info = explore_h5_file(h5_file_path)\n",
    "    \n",
    "    # Example 2: Load JSON and add to HDF5\n",
    "    json_file_path = f\"mol3d_data/final/point_groups_million_{mil}_final.json\"\n",
    "    success = load_json_and_add_to_h5(json_file_path, h5_file_path, 'point_groups')\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\nUpdated HDF5 file structure:\")\n",
    "        explore_h5_file(h5_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "13f42e73-f5be-4783-94e6-a105e3eca6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C1', 'C1', 'C1', 'C1', 'C1', 'C1', 'C1', 'C1', 'C1', 'C2h']\n"
     ]
    }
   ],
   "source": [
    "mil = 1\n",
    "h5_file_path = f\"mol3d_data/molecules3d_million_{mil}.h5\"\n",
    "with h5py.File(h5_file_path, 'r') as f:\n",
    "    point_groups = f['point_groups'][:10]\n",
    "    clean_strings = [s.decode('utf-8') if isinstance(s, bytes) else s for s in point_groups]\n",
    "    print(clean_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2618f95f-c0a1-4242-a08e-84a2d938c499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
